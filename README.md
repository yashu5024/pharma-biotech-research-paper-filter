This project is a CLI-based PubMed scraper that fetches research papers based on a search query. It retrieves PubMed IDs, paper titles, publication dates, authors, affiliations, and corresponding author emails, filtering papers with company affiliations.

ğŸ“‚ Project Structure
graphql
Copy
Edit
pubmed_scraper/
â”‚â”€â”€ pubmed_scraper/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py           # CLI command-line interface script
â”‚   â”œâ”€â”€ pubmed.py        # Fetching and processing PubMed data
â”‚â”€â”€ pyproject.toml       # Poetry project configuration
â”‚â”€â”€ README.md            # Documentation
â”‚â”€â”€ requirements.txt     # Dependencies (if not using Poetry)


ğŸ›  Installation & Setup
1ï¸âƒ£ Install Poetry
Poetry is required to manage dependencies. Install it using:

pip install poetry

poetry new pubmed_scraper
cd pubmed_scraper

poetry install
âœ… This installs all required dependencies, including requests, pandas, and xml.etree.ElementTree.

The program provides a command-line tool called get-papers-list that allows users to search PubMed for papers and filter them based on company affiliations.

poetry run get-papers-list "cancer treatment"
This fetches PubMed papers matching the search query "cancer treatment" and prints the results in JSON format.

ğŸ”¹ 2ï¸âƒ£ Enable Debug Mode (-d)
To see debug information while running the script:

poetry run get-papers-list "cancer treatment" -d
âœ… This prints debug messages, such as fetched PubMed IDs and filtering steps.

ğŸ”¹ 3ï¸âƒ£ Save Results to a CSV File (-f)
To save the results to a file:

poetry run get-papers-list "cancer treatment" -f results.csv
âœ… The output will be stored in results.csv, which can be opened in Excel or any text editor.

ğŸ”¹ 4ï¸âƒ£ Show Help Menu (-h)
To display available options:
